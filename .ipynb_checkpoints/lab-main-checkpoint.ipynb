{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "61e0d3de",
   "metadata": {},
   "source": [
    "# Lab | Revisiting Machine Learning Case Study\n",
    "\n",
    "- In this lab, you will use `learningSet.csv` file which you already have cloned in today's activities. The full process for the week is shown in the PDF file.\n",
    "\n",
    "### Instructions\n",
    "\n",
    "Complete the following steps on the categorical columns in the dataset:\n",
    "\n",
    "- Check for null values in all the columns\n",
    "- Exclude the following variables by looking at the definitions. Create a new empty list called `drop_list`. We will append this list and then drop all the columns in this list later:\n",
    "    - `OSOURCE` - symbol definitions not provided, too many categories\n",
    "    - `ZIP` - we are including state already\n",
    "- Identify columns that have over 50% missing values.\n",
    "- Remove those columns from the dataframe\n",
    "- Perform all of the cleaning processes from the Lesson.\n",
    "- Reduce the number of categories in the column `GENDER`. The column should only have either \"M\" for males, \"F\" for females, and \"other\" for all the rest\n",
    "    - Note that there are a few null values in the column. We will first replace those null values using the code below:\n",
    "\n",
    "    ```python\n",
    "    print(categorical['GENDER'].value_counts())\n",
    "    categorical['GENDER'] = categorical['GENDER'].fillna('F')\n",
    "    ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "1e22fee6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "b05266e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('learningSet.csv', low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "48997c59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make df with categorical data\n",
    "categorical = data.select_dtypes(object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "0c508a1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataframe for percentage null values\n",
    "nulls_percent_df = pd.DataFrame(categorical.isna().sum()*100/len(categorical)).reset_index()\n",
    "nulls_percent_df.columns = ['column_name', 'nulls_percentage']\n",
    "\n",
    "# Dataframe with columns with missing values above \n",
    "columns_above_threshold = nulls_percent_df[nulls_percent_df['nulls_percentage']>50] # as instructed, we use 0.5 (50% as threshold)\n",
    "drop_list = list(columns_above_threshold['column_name'])\n",
    "drop_list.extend(['OSOURCE','ZIP']) # add the two specified useless columns\n",
    "\n",
    "try: # remove specified columns from drop_list\n",
    "    drop_list.remove('WEALTH1')\n",
    "    drop_list.remove('WEALTH2')\n",
    "    drop_list.remove('VETERANS')\n",
    "    drop_list.remove('SOLIH')\n",
    "except:\n",
    "    TypeError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "f93526ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['OSOURCE', 'ZIP']"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "drop_list#OK, there's only the two specified columns..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "68fd2011",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop them from dataframe\n",
    "categorical.drop(drop_list, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "a9f25294",
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply cleaning we did in class: changing column \"MAILCODE\" and replacing all spaces ' ' value with actural Null value\n",
    "categorical['MAILCODE'] = categorical['MAILCODE'].apply(lambda x: x.replace(\" \", \"A\"))\n",
    "categorical = categorical.apply(lambda x: x.replace(\" \", np.NaN))\n",
    "\n",
    "# apply cleaning we did in class: groupping some states into 'other'\n",
    "df = pd.DataFrame(categorical['STATE'].value_counts()).reset_index()\n",
    "\n",
    "df.columns = ['state', 'count']\n",
    "other_states = list(df[df['count']<2500]['state'])\n",
    "\n",
    "categorical['STATE'] = categorical['STATE'].where(~categorical['STATE'].isin(other_states), 'other')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "ed2a53dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean gender column\n",
    "categorical['GENDER'] = categorical['GENDER'].fillna('F') # fillna\n",
    "\n",
    "gend = ['F','M']\n",
    "categorical['GENDER'] = categorical['GENDER'].where(categorical['GENDER'].isin(gend), 'other')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "2cf4ef47",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GENDER\n",
       "F        54234\n",
       "M        39094\n",
       "other     2084\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "categorical['GENDER'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "9245171c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean domain column: split into two columns and drop origional column\n",
    "categorical['DOMAIN'] = categorical['DOMAIN'].fillna('R2')\n",
    "\n",
    "categorical['DOMAIN_A'] = list(map(lambda x: x[0], categorical['DOMAIN']))\n",
    "categorical['DOMAIN_B'] = list(map(lambda x: x[1], categorical['DOMAIN']))\n",
    "\n",
    "categorical = categorical.drop(columns=['DOMAIN'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "4163286b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# repeat from lesson: drop_list and unesseary columns\n",
    "drop_list = []\n",
    "drop_list.extend(['MDMAUD','MAILCODE','NOEXCH','MDMAUD_R', 'MDMAUD_F','MDMAUD_A'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "b55e5281",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fill na for two columns\n",
    "categorical['CLUSTER'] = categorical['CLUSTER'].fillna('40')# 'other' would also be a valid choice\n",
    "categorical['HOMEOWNR'] = categorical['HOMEOWNR'].fillna('U') # assumption: NAN also means 'we don't know'\n",
    "\n",
    "categorical['DATASRCE'] = categorical['DATASRCE'].fillna(0)\n",
    "categorical['DATASRCE'] = categorical['DATASRCE'].convert_dtypes(object)\n",
    "\n",
    "categorical['GEOCODE2'] = categorical['GEOCODE2'].fillna('A')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "efc4ea6e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['MDMAUD',\n",
       " 'MAILCODE',\n",
       " 'NOEXCH',\n",
       " 'MDMAUD_R',\n",
       " 'MDMAUD_F',\n",
       " 'MDMAUD_A',\n",
       " 'RFA_2',\n",
       " 'RFA_3',\n",
       " 'RFA_4',\n",
       " 'RFA_5',\n",
       " 'RFA_6',\n",
       " 'RFA_7',\n",
       " 'RFA_8',\n",
       " 'RFA_9',\n",
       " 'RFA_10',\n",
       " 'RFA_11',\n",
       " 'RFA_12',\n",
       " 'RFA_13',\n",
       " 'RFA_14',\n",
       " 'RFA_15',\n",
       " 'RFA_16',\n",
       " 'RFA_17',\n",
       " 'RFA_18',\n",
       " 'RFA_19',\n",
       " 'RFA_20',\n",
       " 'RFA_21',\n",
       " 'RFA_22',\n",
       " 'RFA_23',\n",
       " 'RFA_24']"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# add more to drop_list and check\n",
    "for col_name in categorical.columns:\n",
    "    if \"RFA\" in col_name:\n",
    "        drop_list.append(col_name)       \n",
    "\n",
    "drop_list.remove('RFA_2R')\n",
    "drop_list.remove('RFA_2A')\n",
    "drop_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "7d1e1b5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop\n",
    "categorical = categorical.drop(columns=drop_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97b12708",
   "metadata": {},
   "source": [
    "# Lab | Feature engineering\n",
    "\n",
    "- In this lab, you will use `learningSet.csv` file which you have already cloned in the previous activities. \n",
    "- Continue working in the same notebook as you did in the previous Lab. \n",
    "\n",
    "### Instructions\n",
    "\n",
    "**Again go through all of the Numerical columns and apply the techniques that were performed in the lesson**\n",
    "\n",
    "Then we will work on cleaning some of the other columns in the dataset using the techniques that we used before in the lessons.\n",
    "\n",
    "- Check for null values in the numerical columns.\n",
    "- After going through the lesson techniques there should only be a few columns left with NaN values to clean.\n",
    "- Use appropriate methods to clean the columns which still contain NaN values.\n",
    "- Use appropriate EDA technique where ever necessary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "e677657b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The numerical dataframe\n",
    "numerical = data.select_dtypes(np.number)\n",
    "numerical = numerical.drop(columns = ['TARGET_B', 'TARGET_D'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "58640e37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply the changing \" \" to NaN on numerical dataframe\n",
    "numerical = numerical.apply(lambda x: x.replace(\" \", np.NaN))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "0a25f36c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# change drop_list for numerical dataframe\n",
    "drop_list = []\n",
    "\n",
    "# Dataframe for percentage null values\n",
    "nulls_percent_df = pd.DataFrame(numerical.isna().sum()*100/len(numerical)).reset_index()\n",
    "nulls_percent_df.columns = ['column_name', 'nulls_percentage']\n",
    "\n",
    "# Dataframe with columns with missing values above \n",
    "columns_above_threshold = nulls_percent_df[nulls_percent_df['nulls_percentage']>25] # as the lesson, we use 0.25 (25% as threshold)\n",
    "drop_list = list(columns_above_threshold['column_name'])\n",
    "\n",
    "try: # remove specified columns from drop_list\n",
    "    drop_list.remove('WEALTH1')\n",
    "    drop_list.remove('WEALTH2')\n",
    "    drop_list.remove('VETERANS')\n",
    "    drop_list.remove('SOLIH')\n",
    "except:\n",
    "    TypeError()\n",
    "\n",
    "# add following columns to drop_list as done in lesson\n",
    "for col in numerical.columns:\n",
    "    if 'ADATE_' in col:\n",
    "        drop_list.append(col)\n",
    "\n",
    "drop_list = drop_list + ['MAXADATE']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "f15e6bb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fillna for several columns\n",
    "numerical['AGE'] = numerical[\"AGE\"].fillna(np.mean(numerical['AGE']))\n",
    "numerical['INCOME'] = numerical['INCOME'].fillna(5.0)\n",
    "numerical['CLUSTER2'] = numerical['CLUSTER2'].fillna(np.ceil(np.mean(numerical['CLUSTER2'])))\n",
    "numerical['WEALTH2'] = numerical['WEALTH2'].fillna(5.0)\n",
    "numerical['TIMELAG'] = numerical['TIMELAG'].fillna(0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "ea76b50b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>column_name</th>\n",
       "      <th>nulls</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>WEALTH1</td>\n",
       "      <td>44732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135</th>\n",
       "      <td>MSA</td>\n",
       "      <td>132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136</th>\n",
       "      <td>ADI</td>\n",
       "      <td>132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137</th>\n",
       "      <td>DMA</td>\n",
       "      <td>132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>315</th>\n",
       "      <td>NEXTDATE</td>\n",
       "      <td>9973</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    column_name  nulls\n",
       "5       WEALTH1  44732\n",
       "135         MSA    132\n",
       "136         ADI    132\n",
       "137         DMA    132\n",
       "315    NEXTDATE   9973"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# drop columns in drop_list and check nan values\n",
    "numerical = numerical.drop(columns=drop_list)\n",
    "df = pd.DataFrame(numerical.isna().sum()).reset_index()\n",
    "df.columns = ['column_name', 'nulls']\n",
    "nullcols = df[df['nulls']>0]\n",
    "nullcols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "227256aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WEALTH1\n",
      "NaN    44732\n",
      "9.0     7585\n",
      "8.0     6793\n",
      "7.0     6198\n",
      "6.0     5825\n",
      "5.0     5280\n",
      "4.0     4810\n",
      "3.0     4237\n",
      "2.0     4085\n",
      "1.0     3454\n",
      "0.0     2413\n",
      "Name: count, dtype: int64\n",
      "MSA\n",
      "0.0       21333\n",
      "4480.0     4606\n",
      "1600.0     4059\n",
      "2160.0     2586\n",
      "520.0      1685\n",
      "          ...  \n",
      "9140.0        1\n",
      "3200.0        1\n",
      "9280.0        1\n",
      "743.0         1\n",
      "8480.0        1\n",
      "Name: count, Length: 299, dtype: int64\n",
      "ADI\n",
      "13.0     7296\n",
      "51.0     4622\n",
      "65.0     3765\n",
      "57.0     2836\n",
      "105.0    2617\n",
      "         ... \n",
      "651.0       1\n",
      "103.0       1\n",
      "601.0       1\n",
      "161.0       1\n",
      "147.0       1\n",
      "Name: count, Length: 205, dtype: int64\n",
      "DMA\n",
      "803.0    7296\n",
      "602.0    4632\n",
      "807.0    3765\n",
      "505.0    2839\n",
      "819.0    2588\n",
      "         ... \n",
      "569.0       1\n",
      "554.0       1\n",
      "584.0       1\n",
      "552.0       1\n",
      "516.0       1\n",
      "Name: count, Length: 207, dtype: int64\n",
      "NEXTDATE\n",
      "NaN       9973\n",
      "9504.0    2253\n",
      "9412.0    1970\n",
      "8703.0    1959\n",
      "9512.0    1870\n",
      "          ... \n",
      "8107.0       1\n",
      "7408.0       1\n",
      "8207.0       1\n",
      "8104.0       1\n",
      "8412.0       1\n",
      "Name: count, Length: 189, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# only the above columns still have nan values, checking MSA, ADI, DMA first, as the number is small, will most likely fill with mode\n",
    "for col in nullcols['column_name'].to_list():\n",
    "    print(numerical[col].value_counts(dropna=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "9596fae5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reviewed the five columns contain null values, and fill them with following methods:\n",
    "\n",
    "#MSA, ADI, DMA: insignificant number of null values, fill with mode\n",
    "numerical['MSA'] = numerical[\"MSA\"].fillna(numerical['MSA'].value_counts().index[0])\n",
    "numerical['ADI'] = numerical[\"ADI\"].fillna(numerical['ADI'].value_counts().index[0])\n",
    "numerical['DMA'] = numerical[\"DMA\"].fillna(numerical['DMA'].value_counts().index[0])\n",
    "\n",
    "#WEALTH1: fill with median, same as WEALTH2\n",
    "numerical['WEALTH1'] = numerical['WEALTH1'].fillna(5.0)\n",
    "\n",
    "#NEXTDATE: read column description, assuming nan means donor didn't give a second gift, so fill with 0.0 for date\n",
    "numerical['NEXTDATE'] = numerical['NEXTDATE'].fillna(5.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "92f82b11",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>column_name</th>\n",
       "      <th>nulls</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [column_name, nulls]\n",
       "Index: []"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check and compleat\n",
    "df = pd.DataFrame(numerical.isna().sum()).reset_index()\n",
    "df.columns = ['column_name', 'nulls']\n",
    "nullcols = df[df['nulls']>0]\n",
    "nullcols"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
